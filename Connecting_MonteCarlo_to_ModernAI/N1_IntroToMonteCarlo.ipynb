{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPF2QPsGc4GHIK3n+8kL+es",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GDS-Education-Community-of-Practice/DSECOP/blob/daleas_module/Connecting_MonteCarlo_to_ModernAI/N1_IntroToMonteCarlo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Notebook 1: Introduction to Monte Carlo Methods and Markov Chains\n",
        "Ashley Dale\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In this notebook, you will learn the following concepts:\n",
        "\n",
        "*   The difference between a model and a simulation\n",
        "*   The definition of a Markov Chain, and how to implement one\n",
        "*   How to implement Monte Carlo integration\n",
        "*   How to evaluate simulation results using standardized metrics\n",
        "\n",
        "These concepts are useful review for the next notebook on the Ising Model.\n"
      ],
      "metadata": {
        "id": "NfcPTtFDyLop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup Python Environment\n"
      ],
      "metadata": {
        "id": "Rb11yXOGzpyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # used for mathematical operations\n",
        "import matplotlib.pyplot as plt # used to visualize results\n",
        "from tqdm import trange # prints a nice loading bar for the notebook"
      ],
      "metadata": {
        "id": "ixq23jB7zq3G"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Background Information\n",
        "\n",
        "The main computational approach presented in this module is known as ***The Metropolis-Hastings Algorithm***, and was [presented in a paper](https://aip.scitation.org/doi/abs/10.1063/1.1699114) authored by Nicholas Metropolis, Ariana Rosenbluth, Marshall Rosenbluth, Augusta Teller, and Edward Teller.  The authors [developed the algorithm](https://aip.scitation.org/doi/abs/10.1063/1.1632112) during their time at Los Alamos National Laboratory in New Mexico USA, and it was specifically designed to run on [MANIAC, an early vacuum tube computer](https://discover.lanl.gov/news/0412-maniac/).  MANIAC was slow compared to modern machines; in a game of chess, [it required 20 minutes between moves](https://discover.lanl.gov/news/0412-maniac/).  However, this computational approach allowed a breakthrough in physics: a way to predict a physical outcome without having an analytical solution to the differential equation that describes a system's state.\n",
        "\n",
        "The following sections will walk you through basic ideas and definitions required for understanding the computational approach.  For more on the physics, continue to **Notebook 2: Ising Model Simulation**. \n",
        "\n"
      ],
      "metadata": {
        "id": "kv9NgAXIzmem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modeling vs. Simulation\n",
        "\n",
        "In general, a *model* is an object that represents a system; it is not the system itself.  Examples include mathematical equations, mechanical objects such as dice or an [orrery](https://en.wikipedia.org/wiki/Orrery), and deep-neural networks (DNN) used in machine learning.\n",
        "\n",
        "A *simulation* takes a model and makes predictions about the system by varying model parameters.  See the table below for some examples on how models and simulations relate.\n",
        "\n",
        "|Original System | Model | Parameter varied during simulation | Simulation Prediction |\n",
        "|--- | --- | --- | --- |\n",
        "|Object in free fall| $\\Delta y = v_o \\Delta t + 0.5 a(\\Delta t)^2$ <br> where $\\Delta y$ is the change in position, <br> $a$ is the acceleration, <br> $v_o$ is the initial velocity and <br > $t$ is the change in time. | $\\Delta t$, change in time | Change in position $\\Delta y$ after time $\\Delta t$\n",
        "|Customer Ice Cream Selection | Dice | Dice physical configuration | Number on dice correlates to ice cream flavor |\n",
        "|Solar System| Orrery | Planet objects start in an initial position, <br> a handle is cranked to change this position | New planetary positions |\n",
        "|Human identifies cat or dog | DNN | The input image to the network is changed | The input is labeled \"cat\" or \"dog\" |\n",
        "\n"
      ],
      "metadata": {
        "id": "BYWqTwBy0KOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validating a model and its simulation can be extremely challenging.  Different approaches depend on the data and information available to you.  Consider the following situations:\n",
        "\n",
        "**Case 1**: You have simulation results and experimental results. This is an ideal case for a physicist, as physics models are designed to predict physical phenomena.  \n",
        "\n",
        "**Case 2**: You have simulation results for one simulation and no experimental results.  In this case, you will want to see how self-consistent your simulation results are, <br> and if the outputs fall within an expected range.  <br>\n",
        "\n",
        "**Case 3**: You have simulation results for multiple kinds of simulations, but no experimental results.  Here, you will want to compare whether or not the simulations predict the same thing.\n",
        "\n",
        "The metric used to evaluate a simulation will depend on which case you have.  See the table for different metrics:\n",
        "\n",
        "\n",
        "| Metric | Equations | Notes |\n",
        "| ----- | ----- | ----- |\n",
        "| Mean<br>Square<br>Error (MSE) | $\\frac{1}{n}\\sum_{i=1}^n \\left(Y_i - \\hat{Y}_i\\right)^2$ where<br> $Y_i$ is the expected value and $\\hat{Y}_i$ is the predicted value| The average distance <br> between two datasets |\n",
        "| Percent<br>Error |$\\left (Y_i - \\hat{Y}_i \\right)/Y_i \\times 100 $ where<br> $Y_i$ is the expected value and $\\hat{Y}_i$ is the predicted value |Can only be used when <br>there is an accepted value, i.e. Case 1|\n",
        "| Percent<br>Difference | $ 2\\left| Y_i - \\hat{Y_i} \\right| / (Y_i + \\hat{Y_i})$ where<br> $Y_i$ is the first predicted value and $\\hat{Y}_i$ is the second predicted value| Good for Cases 2 and 3 |\n",
        "| Standard<br>Error | $\\frac{\\sigma}{\\sqrt{n}}$ where $\\sigma$ is the standard deviation and <br>$n$ is the number of data points considered in the standard deviation | Good for Case 3 |\n",
        "\n"
      ],
      "metadata": {
        "id": "9Yf4q7FpY64p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stochastic Systems & Probabilistic Model Review\n",
        "Many real world systems do not have a single outcome for a single input, and there is some uncertainty as to which outcome you will have.  These systems are called *stochastic*.  They can be modeled using probability distributions.\n",
        "\n",
        "---\n",
        ">**An Example of a Stochastic System and Probability Model (Featuring my Cat)** <br>\n",
        ">\n",
        ">Consider my cat. When I greet him in the morning, he usually wants to be pet immediately, but sometimes he wants to be fed breakfast first.  After collecting much data about my cat, I can model this behavior using an equation that has no theory or assumptions behind it (it is *empirical*).  The probability that my cat wants to be pet first is:\n",
        ">\n",
        "> <center>$P(Cat\\ wants\\ pets) = \\frac{\\#\\ Times\\ He\\ Asks\\ For\\ Pets}{\\#\\ Times\\ I\\ Say\\ Good\\ morning}$</center>\n",
        ">\n",
        ">Because he only wants pets or breakfast, I can also write this equation:\n",
        ">\n",
        "><center>$P(Cat\\ wants\\ breakfast) = 1 - P(Cat\\ wants\\ pets)$</center>\n",
        ">\n",
        ">This means there is a 100% chance that he wants either pets or breakfast, so \n",
        ">\n",
        "><center>$P(Cat\\ wants\\ breakfast\\ OR\\ pets) = P(Cat\\ wants\\ breakfast) + P(Cat\\ wants\\ pets) = 1$</center>\n",
        ">\n",
        ">For the same input when I see him in the morning, my cat has two outputs.  (That's it.  He is not a very smart cat.)  However, after living with him for 18 years, we are pretty good friends, and I know that most mornings he prefers to be pet before eating his food.  In fact, I would say that this is the case 75% of the time:\n",
        ">\n",
        "><center>$P(Cat\\ wants\\ pets) = 0.75$</center>\n",
        ">\n",
        ">And this means that I automatically go to pet him first before I head to the kitchen to make him breakfast.  He's done a good job conditioning me.\n",
        "\n",
        "---\n",
        "\n",
        "In the example above, the model is very simple since it only has two outcomes, so I would use a [Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution) to model my cat.  Here is a reminder of some other common probability distributions.  If you are not familiar with these, take a few minutes to review them:\n",
        "\n",
        "\n",
        "Distribution Name | Distribution Equation | Comments\n",
        "--- | --- | ---\n",
        "[Normal](https://en.wikipedia.org/wiki/Normal_distribution)|$f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}}e^{-\\frac{1}{2} \\left(\\frac{x-\\mu}{\\sigma}\\right)^2} $|Gaussian!  $\\mu$ is the mean and $\\sigma$ is the standard deviation\n",
        "[Uniform](https://en.wikipedia.org/wiki/Continuous_uniform_distribution)|$f(x) = \\frac{1}{b-a}$ for $a \\le x \\ge b$ and <br> 0 everywhere else |All outcomes in the range of $a$ to $b$ are equally likely\n",
        "[Boltzmann](https://en.wikipedia.org/wiki/Boltzmann_distribution)|$p_i = \\frac{e^{-E_i/(kT)}}{\\Sigma^M_{j=1} e^{E_j/(kT)}}$|The probability the system is in a specific state depends on the temperature\n",
        "\n"
      ],
      "metadata": {
        "id": "kdvOx8IeHQ2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Markov Chains\n",
        "\n",
        "A *Markov Chain* is a stochastic model that describes a sequence.  The probability of the next item in the sequence is only determined by the last item in the sequence.\n",
        "[<img src=https://upload.wikimedia.org/wikipedia/commons/2/2b/Markovkate_01.svg alt=\"Picture of two-state Markov Chain with probability of transitioning between states.  Source: Wikipedia\" align=\"left\" width=300>](https://commons.wikimedia.org/wiki/File:Markovkate_01.svg)\n",
        "\n",
        "In the figure to the left (*source: [Wikipedia](https://commons.wikimedia.org/wiki/File:Markovkate_01.svg)*), the Markov Chain sequence has two items: state $E$ and state $A$.  The arrows show how to get from one state to the next, and the probability of making each state change is next to each arrow.  Here, we can say that there is a higher probability of staying in state $A$ than in state $E$ because the probability value next to the arrow from $E$ to $A$ is 0.7 (compared to the probability value of 0.3 from $E$ to $E$), and the probability  value from $A$ to $A$ is 0.6 (compared to the probability value of 0.4 for $A$ to $E$).  It is always more likely to be in state $A$ than in state $E$, even if we start the system in state $E$.  \n",
        "\n",
        "The most important thing to notice is that the Markov Chain does not keep track of how long it has been in a particular state, or what states it has already been to.  There is no memory of where the system has already been; the only thing you need to make a prediction for what state comes next in the sequence is knowledge of the current system state.  This makes it a very powerful modeling approach; the key is correctly generating the probabilities next to the arrows for your particular use case.\n",
        "\n"
      ],
      "metadata": {
        "id": "8JhDtJ0XNX2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Monte Carlo Sampling\n",
        "\n",
        "*Monte Carlo Sampling* is useful when you have a model for your probability distribution like the ones in the table above, but do not know the exact probability of the outcome you are trying to predict.  Basically, you guess the probability numbers next to the orange arrows in the Markov Chain, and see if your guess makes your system model behave like the real-world one.\n",
        "\n",
        "---\n",
        ">**An Example of Monte Carlo Sampling (Also Featuring My Cat)**\n",
        ">\n",
        ">This is where I admit that I have not, in fact, recorded my cat's preferences every morning for the past 18 years and then compiled statistics for my Bernoulli distribution above.  However, I don't actually need to in order to have an experimentally valid prediction for his behavior.  My experimental procedure might go like this:\n",
        ">\n",
        "> 1. Flip a coin before I do anything else\n",
        "> 2. If the coin lands \"heads\" up, I will write down his response in my lab notebook\n",
        "> 3. If the coin lands \"tails\" up, I won't bother to write anything down\n",
        ">\n",
        ">My decision to collect data is randomly decided by the coin toss.  If my coin has 1:1 odds of landing heads or tails, this means I am collecting data only 50% of the time.  The technical term for this is *randomly sampling the distribution*, because I am not collecting every data point – only some of them – and I am choosing which ones to keep randomly.  \n",
        ">\n",
        "> 4. I decide how many times to repeat steps 1-3.  \n",
        ">\n",
        ">The more data I collect, the better my approximation of the actual probability for my cat's behavior.  However, there are practical considerations.  I can't collect data forever; but too few data points will not let me make good predictions.  The exact way I determine how many points to collect might depend on how confident I need to be about my prediction, how quickly my data forms a nice pattern, etc.\n",
        "---\n",
        "\n",
        "The combination of Markov Chains with Monte Carlo sampling is extremely powerful, and is what we will explore in the next notebook.\n"
      ],
      "metadata": {
        "id": "L0raUAP4yxy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercises\n",
        "\n",
        "Complete the exercises below."
      ],
      "metadata": {
        "id": "o6OP4uxq1ooP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Programming Exercise 1: Markov Chain\n",
        "\n",
        "Below is a partially completed program that simulates the Markov Chain model shown in the figure above.  \n",
        "\n",
        "a) Complete the program, and report the average number of steps it takes to change to state $A$ when starting in state $E$.  Include the uncertainty (i.e. [standard error](https://en.wikipedia.org/wiki/Standard_error)) in your reported number.  You should make additional code cells in your notebook to keep track of your data and present your results.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Here is the transition probability table:\n",
        "\n",
        "State Change | Probability \n",
        "--- | ---\n",
        "EE | 0.3\n",
        "EA | 0.7\n",
        "AE | 0.4\n",
        "AA | 0.6"
      ],
      "metadata": {
        "id": "0nlkg2yqJngc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OZqVToXUx1qG"
      },
      "outputs": [],
      "source": [
        "# Here are some variables to get you started\n",
        "\n",
        "# Decide how many steps to make the simulation run\n",
        "num_steps = 100\n",
        "\n",
        "# Define a starting state: \n",
        "current_state = 'E' \n",
        "\n",
        "# Define an ending state:\n",
        "end_state = 'A'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide on a probability distribution function for the simulation \n",
        "# (uncomment one of the probability lines in the function): \n",
        "\n",
        "def get_probability(): \n",
        "  # This function returns a probability value when called\n",
        "\n",
        "  # --> This is a sample from a uniform distribution from numpy\n",
        "  \n",
        "  #prob = np.random.uniform(0, 1, 1)\n",
        "\n",
        "  # --> This is a sample from a normal distribution from numpy\n",
        "  # --> It is centered at 0.5 to match the default uniform distribution\n",
        "  \n",
        "  #prob = np.random.normal(loc=0.5, size=1)\n",
        "  \n",
        "  return prob"
      ],
      "metadata": {
        "id": "O4Wkbgt-dkCC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we run the simulation\n",
        "\n",
        "for step in range(num_steps):\n",
        "  p = get_probability()\n",
        "\n",
        "  # --- HERE IS THE STATE MACHINE CODE --- #\n",
        "\n",
        "  # --> The first logical case is written for you\n",
        "\n",
        "  # If the state is currently 'E' \n",
        "  # and transition probability is less than or equal to 0.3\n",
        "  if current_state == 'E' and p<=0.3:\n",
        "    \n",
        "    # stay in state 'E'\n",
        "    current_state = 'E'\n",
        "  \n",
        "  # --> Now you write the next cases:\n",
        "\n",
        "  # if the state is currently 'E' \n",
        "  # and the transition probability is greater than 0.3\n",
        "  if current_state == and p> :\n",
        "    \n",
        "    # move to state 'A'\n",
        "    current_state = \n",
        "\n",
        "  # if the state is currently 'A'\n",
        "  # and the transition probability is less than equal to 0.4\n",
        "  if current_state == and p<= :\n",
        "    \n",
        "    # move to state 'E'\n",
        "    current_state =\n",
        "\n",
        "  # if the state is currently 'A'\n",
        "  # and the transition probability is greater than 0.4\n",
        "  if current_state == and p> :\n",
        "\n",
        "    # stay in state 'A'\n",
        "    current_state = \n",
        "  # --- STATE MACHINE CODE ENDS --- #\n",
        "\n",
        "  # Stop updating when the system has transitioned to the end state\n",
        "  if current_state == end_state:\n",
        "    break\n",
        "\n",
        "print(\"Ending state achieved after \"+str(step+1)+\" iterations\")\n"
      ],
      "metadata": {
        "id": "llr1UfKcM0j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store your results here:\n",
        "\n",
        "data_EtoA = []#STORE YOUR VALUES IN THIS LIST\n",
        "mean_EtoA = #<WRITE YOUR AVERAGE VALUE CALCULATION HERE>\n",
        "stderr_EtoA = #<WRITE YOUR STANDARD ERROR CALCULATION HERE>\n",
        "\n",
        "print(f\"# of tries to transition from E to A: {mean_EtoA} +/- {stderr_EtoA}\")\n",
        "\n",
        "data_AtoE = []#STORE YOUR VALUES IN THIS LIST\n",
        "mean_AtoE = #<WRITE YOUR AVERAGE VALUE CALCULATION HERE>\n",
        "stderr_AtoE = #<WRITE YOUR STANDARD ERROR CALCULATION HERE>\n",
        "\n",
        "print(f\"# of tries to transition from A to E: {mean_AtoE} +/- {stderr_AtoE}\")"
      ],
      "metadata": {
        "id": "uAwPwYbcd3yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) The program above can be written much more simply, and the experiment can be done more efficiently by defining a function for the whole experiment that lets the user automate the results. \n",
        "\n",
        "\n",
        "*   Define a new function \"MarkovChainExperiment\" (outlined for you below) that takes as an inputs the number of times to run the experiment, the initial state, and the final state and returns a list containing how many steps it took to change the state for each time the experiment was run.  The function should let the user specify how many times to simulate the Markov Chain, run the simulation that number of times, and then return all of the results at once.  *Hint*: You will need to add another for loop.\n",
        "\n",
        "*   Rewrite the state machine code using only two if-statements\n",
        "\n",
        "*   Test your function by calling it in a new cell, and making a histogram of the results for 1 million experiments each of \"E to A\" and \"A to E\".\n"
      ],
      "metadata": {
        "id": "gAy0LyufwT6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def MarkovChainExperiment():\n",
        "\n",
        "  # Begin by initializing the \n",
        "  # current state with the value passed into the function\n",
        "  current_state = \n",
        "\n",
        "  # define a variable to track results\n",
        "  results = [] #this is a python list data type to make things easy\n",
        "\n",
        "  # --> Now run the experiment repeatedly:\n",
        "\n",
        "    # for each experiment trial:\n",
        "\n",
        "        # for each step in the range of steps to try:\n",
        "        for n in range(num_steps):\n",
        "          p = get_probability()\n",
        "\n",
        "          # --- HERE IS THE STATE MACHINE CODE --- #\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          # --- STATE MACHINE CODE ENDS --- #\n",
        "\n",
        "          # Stop updating when the system has transitioned to the end state\n",
        "          if current_state == end_state:\n",
        "            # update the results list by appending\n",
        "            # the number of steps just finished to the end of the list\n",
        "\n",
        "            break\n",
        "\n",
        "            \n",
        "  return results\n"
      ],
      "metadata": {
        "id": "uDNsRvvuevU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the function here with the necessary parameters\n",
        "\n",
        "data_EtoA = MarkovChainExperiment()\n",
        "data_AtoE = MarkovChainExperiment()"
      ],
      "metadata": {
        "id": "-UdJrk8Ggcat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a figure showing the histogram distribution of the number of steps it took to change states for both `data_EtoA` and `data_AtoE`.  \n",
        "\n",
        "* [How to make histograms with Matplotlib.pyplot](https://pythonspot.com/matplotlib-histogram/)"
      ],
      "metadata": {
        "id": "lUG_EWlIgyZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put your plotting code here"
      ],
      "metadata": {
        "id": "12unyL8PgqXr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Programming Exercise 2: Monte Carlo Integration\n",
        "\n",
        "Let's dive a little bit deeper into the idea of Monte Carlo sampling through an exercise where Monte Carlo sampling is used to improve a numerical integration result.\n",
        "\n",
        "Numerical integration uses the rectangle approximation to find the area under a curve.  The analytical notation we are used to seeing for a definite integral\n",
        "\n",
        "<center> $F = \\int_a^b f(x) dx $ </center>\n",
        "\n",
        "can be expressed as a [numerical approximation that adds up $n$ rectangles under the curve $f(x)$](https://mathworld.wolfram.com/NumericalIntegration.html).  The more rectangles used to calculate the area, the better the approximation becomes.\n",
        "\n",
        "Monte Carlo Integration improves this approach by randomly picking which rectangles to add up next and approximating $F$ as $\\langle F^N \\rangle$:\n",
        "\n",
        "<center> $\\langle F^N \\rangle = \\frac{b-a}{N-1} \\sum_{i=0}^{N} f(X_i)$ </center>\n",
        "\n",
        "where $N$ is the number of times a new value $X_i$ is chosen from a probability distribution for range $a$ to $b$.  Therefore, \n",
        "\n",
        "<center> $lim_{N→∞} \\langle F^N \\rangle = F $ </center>\n",
        "\n",
        "The question becomes, what is the best way to choose $X_i$ to match the real system?  The goal is to get the best approximation as quickly as possible.\n",
        "\n",
        "---\n",
        "###For this exercise, do the following:\n",
        "\n",
        "1. Choose a definite expression from the table below (or your instructor might tell you which one to pick):\n",
        "\n",
        ">||Function|Interval|Notes|\n",
        "|---|:-----------------------:|---|---|\n",
        "|1. |$x = \\int_0^1 -10t\\ dt$| $t$ is time; $t = [0, 1]$ |Gives position at time $t$ for this system|\n",
        "|2. |$\\Delta S = \\int_{300}^{400}\\frac{mc}{T}\\ dT $|$m$ is mass; $m=1$ kg<br> $c$ is specific heat capacity; $c = 4190$ J/kg K<br>$T$ is temperature; $T = [300, 400]$|Change in entropy for thermal processes|\n",
        "|3. |$\\Phi = \\int_1^2 \\frac{Q}{4 \\pi \\epsilon_o r^2} dr$|$r$ is distance; $r = [1, 2]$<br>$\\epsilon_o$ is the Permittivity of Free Space<br>$Q$ is the charge; $Q = 1$C|$\\Phi$ is the electric potential energy <br>gained by moving along line $r$|\n",
        "|4. |$I = \\int_0^\\infty \\frac{2 \\pi h c^2}{\\lambda^5(e^{hc/\\lambda k T} - 1)}\\ d\\lambda$|$h$ is Planck's constant<br> $c$ is speed of light <br> $k$ is Boltzmann's Constant <br> $T$ is the absolute temperature; T = 400K <br> $\\lambda$ is wavelength; $\\lambda = [0, \\infty]$|Planck's radiation law; <br>Integrating gives Stefan Boltzmann Law|\n",
        "\n",
        "2. Analytically integrate it for the region and values provided, and record your answer in the `analytical_result` variable below\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PHlFkdNM6ozG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analytical_result = "
      ],
      "metadata": {
        "id": "oVd9a0w46nya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Write the expression to be integrated as a python function.  For example, if I want to integrate the expression\n",
        "\n",
        "<center> $F = \\int 3x^2 + 17\\ dx$</center>\n",
        "\n",
        "then my integrand is\n",
        "\n",
        "<center> $f(x) = 3x^2 + 17$</center>\n",
        "\n",
        "and I would write the following function:\n",
        "```\n",
        "def integrand(x):\n",
        "    f_x = 3*np.power(x, 2) + 17\n",
        "    return f_x\n",
        "```\n",
        "This function takes `x` as my function argument, and returns the calculated value `f_x`.  Note that I am not yet evaluating the limits of my integrand."
      ],
      "metadata": {
        "id": "G6hIpOJoiMQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helpful constants:\n",
        "pi = np.pi #unitless\n",
        "c = 2.99E8 #m/s\n",
        "h = 6.62607015E-34 #J\n",
        "k = 1.380649E-23 #J/K\n",
        "epsilon = 8.854187817E-12 #F/m\n",
        "sigma = 5.6704E-8 #W/(m^2 K^4)"
      ],
      "metadata": {
        "id": "4-vvOg-kiQi3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def integrand(x):\n",
        "  f_x = #<DEFINE YOUR INTEGRAND HERE>\n",
        "  return f_x"
      ],
      "metadata": {
        "id": "5iqDJkfgiSvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Randomly choose values for `x` from a distribution between the limits of the definite integral. \n",
        ">*Hint*: if one of your limits is $\\infty$, it is okay to approximate it with a large number.  Another way to do it is to plot [x, f(x)] and visually estimate the most important region of your integration."
      ],
      "metadata": {
        "id": "kUSp8FrriiR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lower_limit = \n",
        "upper_limit = \n",
        "num_x_vals = \n",
        "x_vals = np.random.uniform(lower_limit, upper_limit, num_x_vals)"
      ],
      "metadata": {
        "id": "_g2DMq67jEZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Calculate the `f_x` values:"
      ],
      "metadata": {
        "id": "12-zuN_PjUEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = integrand(x_vals)"
      ],
      "metadata": {
        "id": "j9OTL1uIjWHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Add them all together using the approximation: \n",
        "<center> $\\langle F^N \\rangle = \\frac{b-a}{N-1} \\sum_{i=0}^{N} f(X_i)$ </center>\n"
      ],
      "metadata": {
        "id": "7qo4EHVSjcPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write code to calculate the equation above here\n",
        "approx_int = #<WRITE YOUR EQUATION HERE>\n",
        "print(f\"The Monte Carlo approximation is {approx_int}\")"
      ],
      "metadata": {
        "id": "ozJOfc7bjght"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Calculate the error between the `approx_int` and the `analytical_result` variables using one or more of the metrics discussed above"
      ],
      "metadata": {
        "id": "W52Zw7CvjwgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "error = \n",
        "print(f\"The error is {error}\")"
      ],
      "metadata": {
        "id": "UrdYX3BqjwEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Finally, we want to visualize how the error decreases as the number of random trials `num_x_vals` increases.  Write code to the do the following:\n",
        "\n",
        "* Using the error metric you decided on above, write a for-loop that calculates the error as a function of the number of points you sampled.  For example, calculate the error when you summed two values of $\\langle F^N \\rangle$, then calculate the error for three summed values of $\\langle F^N \\rangle$, and so on until you have calculated the errors for the full range of $\\langle F^N \\rangle$.\n",
        "\n",
        "* IMPORTANT: You do not need to re-do the experiment to calculate this analysis.  Use the `y` list variable.\n",
        "\n",
        "* Make a figure showing how the error changes with the number of values in the sum.\n",
        "\n",
        "* Answer these questions: What can you tell about the trend in the error?  Would your approximation benefit from additional calculations (increasing the number of `num_x_vals`?  Could you have done fewer calculations?"
      ],
      "metadata": {
        "id": "9_M6EOmQPhbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the code in this cell:\n",
        "\n",
        "# Make a variable to store your error calculations in\n",
        "error_data = []\n",
        "\n",
        "# First I loop over all of the values of N\n",
        "for idx in trange(2, num_x_vals):#I am starting my index at 2 to avoid division by zero\n",
        "\n",
        "  #Next, adjust the integral expression so it doesn't use all of the points at once\n",
        "  approx_int = \n",
        "\n",
        "  # Calculate the error\n",
        "  err = \n",
        "\n",
        "  # Then save the error value to the error_data array\n",
        "  error_data.append(perre)"
      ],
      "metadata": {
        "id": "KT380AMPPk9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your plotting code here"
      ],
      "metadata": {
        "id": "JnaDmgRsQAFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Answer the questions here:*"
      ],
      "metadata": {
        "id": "6ZI7Pj5aQC70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question 1: Model vs Simulation\n",
        "In your own words, describe the difference between a model and a simulation.  Give your own example of a model, and how you would simulate it."
      ],
      "metadata": {
        "id": "jQUlbD3vG-zL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Enter your answer here*"
      ],
      "metadata": {
        "id": "YaAtZl8qPNOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question 2: Markov Chain\n",
        "In your own words, describe a Markov Chain and its properties. Give your own example of a stochastic system and how you would implement it."
      ],
      "metadata": {
        "id": "JUOEG8p9PTZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Enter your answer here*"
      ],
      "metadata": {
        "id": "ZDsUu0Z8PkRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Additional Readings\n",
        "1. [Metropolis, Nicholas, et al. \"Equation of state calculations by fast computing machines.\" The journal of chemical physics 21.6 (1953): 1087-1092.](https://aip.scitation.org/doi/abs/10.1063/1.1699114)\n",
        "\n",
        "2. [Van Ravenzwaaij, Don, Pete Cassey, and Scott D. Brown. \"A simple introduction to Markov Chain Monte–Carlo sampling.\" Psychonomic bulletin & review 25.1 (2018): 143-154.](https://link.springer.com/article/10.3758/s13423-016-1015-8?wt_mc=Other.Other.8.CON1172.PSBR%20VSI%20Art09%20&%20utm_medium=other%20&%20utm_source=other%20&%20utm_content=2062018%20&%20utm_campaign=8_ago1936_psbr%20vsi%20art09)\n",
        "\n",
        "3. [Victor Cumer. \"The basics of Monte Carlo integration\". Towards Data Science (2020)](https://towardsdatascience.com/the-basics-of-monte-carlo-integration-5fe16b40482d)\n",
        "\n",
        "4. [Nicholas Lewis. \"70 years of electronic computing.\" Los Alamos National Laboratory (2022)](https://discover.lanl.gov/news/0412-maniac/)\n",
        "\n",
        "5. [Rosenbluth, Marshall N. \"Genesis of the Monte Carlo algorithm for statistical mechanics.\" AIP Conference Proceedings. Vol. 690. No. 1. American Institute of Physics, 2003.](https://aip.scitation.org/doi/abs/10.1063/1.1632112)"
      ],
      "metadata": {
        "id": "iF7NOm4X0k3b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FVvjaVKpQy_3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
