{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKL7_DS_lIOC",
        "outputId": "6db1e072-8ad4-4014-e3dd-e65cafbc02bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/DSECOP/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import curve_fit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive/\")\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/DSECOP/Colab Notebooks/\")\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Pull Plots\n"
      ],
      "metadata": {
        "id": "uiPID_vX6lFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this notebook, we'll learn about residual plots and pull plots. We'll talk about the information that these plots provide us, and practice creating the plots ourselves."
      ],
      "metadata": {
        "id": "427xOo0teeVc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How can we gain more information about a model's goodness of fit?\n",
        "\n"
      ],
      "metadata": {
        "id": "vVSnKvTdh819"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous notebook, we learned about the $\\chi^2$ test statistic. There are two important limitations to this test statistic. The first is that the $\\chi^2$ test only *really* works for categorical data, which \"number of counts\" only barely squeaks under. The second is that the $\\chi^2$ test statistic is a single number, while we might want to evaluate our model fit at a specific part of our histogram (perhaps at the tails).\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "0_HoCHUMetdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we fit an analytical function to a dataset, we never expect there to be *perfect* agreement between the two. The discrepancies broadly fall into two categories:\n",
        "\n",
        "1. **The dataset contains statistical fluctuations.** If we rolled a six-sided die six times, we would never expect to roll one of every number exactly once. Similarly, if we observe the decays of a radioactive sample, we expect the distribution to be Poissonian, but not *perfectly* so. We might also expect less-than-perfectly-precise detector performance to provide a good amount of statistical error.\n",
        "\n",
        "2. **The chosen fit function is a poor one.** Fitting a linear fit function to quadratically distributed data should produce a fit that is obviously bad to the unaided eye. But sometimes, the a wrong model can be only subtly off. Can we trust our eyes to discriminate a quadratic function from a quartic one?\n",
        "\n",
        "The first type of discrepancy is unavoidable in experimental processes. However, we might be able to diagnose and correct for the second type of discrepancy. Plotting the *residuals* of a fit can be a useful tool to this end."
      ],
      "metadata": {
        "id": "qQgHIIykfggL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To start off, let's practice what we learned before! \n",
        "\n",
        "**Activity**: Read in the dataset `geiger_counts_A.txt`. Histogram the dataset, then use `scipy.optimize.curve_fit` to fit the data to a Poisson and a Gaussian distribution. Plot the dataset and both fits on the same plot. "
      ],
      "metadata": {
        "id": "aCOHH5UCncAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_location = \"datasets/geiger_counts_A.txt\"\n",
        "\n",
        "# Your code here"
      ],
      "metadata": {
        "id": "t2rXvRZ1wm2p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the residuals of a fit\n",
        "\n"
      ],
      "metadata": {
        "id": "1I8yv9LB1t7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The name \"residuals\" should give some intuition about what we're looking for here -- they're the parts of our data that aren't perfectly captured by our fit function, or that are \"left over\".\n",
        "\n",
        "Residuals are defined bin-wise, so they give us much more information than a single test statistic. The residual $r_i$ (defined for a given bin $b_i$) is defined as \n",
        "\n",
        "$$r_i = \\textrm{actual value in bin } b_i - \\textrm{fit value in bin } b_i.$$\n",
        "\n",
        "How can we use residuals to discriminate between a model that is the best fit for a given dataset that contains many statistical fluctuations, vs. a model that is a poor fit? Statistical fluctuations are random, so they cause deviations of data from what's expected that would sometimes be greater than the underlying model, and sometimes less. In contrast, if the residuals for a given fit are always *positive*, this means that the fit function usually *underestimates* the data. This could be an indication that the fit function isn't great."
      ],
      "metadata": {
        "id": "B-H-dauJhI1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activity**: Plot the residuals of the Poisson and Gaussian fits to the dataset. It might be helpful to also plot a horizontal line at y = 0."
      ],
      "metadata": {
        "id": "EU8gmke7pD67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "OEUy2o8DyuNE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling residuals to data: pull plots"
      ],
      "metadata": {
        "id": "CojbA_kXp2MZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that for histograms of counts, the error for a given bin due to statistical fluctuations is $\\sqrt{n}$, where $n$ is the number of counts in the bin. This means that we would expect the residuals to be larger for a bin with more counts, as there is a greater chance of getting a larger statistical fluctuation away from an expected value. Is there a similar quantity to residuals that normalizes for the number of counts in a given bin?\n",
        "\n",
        "The scaled alternative to residuals are *pulls*. The pulls $p_i$ are defined as \n",
        "\n",
        "$$p_i = \\frac{\\textrm{actual value in bin } b_i - \\textrm{fit value in bin } b_i}{\\text{standard deviation associated with the fit value in bin }b_i}.$$\n",
        "\n",
        "So the pull in a given bin is just the residual for that bin with a scaling factor to account for how large we would expect the statistical fluctuation in that bin to be. So while we expected the size of the residuals to vary based on the number of counts in the associated bin, we would expect the pulls to be on the order of 1 across all bins for a good fit."
      ],
      "metadata": {
        "id": "lTu0l_WapjWf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activity**: Plot the pulls of the Poisson and Gaussian fits to the dataset. It might be helpful to also plot a horizontal line at y = 0. Based on the pull plot, make a statement about which fit is a better one to the observed data."
      ],
      "metadata": {
        "id": "iywOpIPrKsL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "yjhEigaL2ETc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Your answer here*"
      ],
      "metadata": {
        "id": "dEHmgcFzEudu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Activity**: Using `plt.subplots`, plot the (1) data and fit functions, and (2) pull plot using the same x-axis."
      ],
      "metadata": {
        "id": "Ju4l-LK9LBDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "9elns6_Q3iWU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Notebook finished*"
      ],
      "metadata": {
        "id": "Po60cuudhdT8"
      }
    }
  ]
}