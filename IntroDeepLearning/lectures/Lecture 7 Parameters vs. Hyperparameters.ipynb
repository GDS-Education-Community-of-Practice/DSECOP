{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6222e6d",
   "metadata": {},
   "source": [
    "# Lecture VII: Parameters vs. Hyperparameters\n",
    "\n",
    "In the logistic regression model, the output and input are related to each other by using two sets of parameters: $\\omega$ and $b$. These are called **model parameters**. But we also use an activation function such as sigmoid function $\\sigma(z)$. Do we call it another parameter of the model? The answer is no. We actually define it manually and they did not change during the *learning process*. Therefore, an activation function is a **Hyperparameter** in the neural network. In general, *Hyperparameters* are those parameters that are explicitly defined by the user to control the learning process, whereas *Model parameters* are configuration variables that are internal to the model, and a model learns to modify them. \n",
    "\n",
    "Another example of hyperparameters is the learning rate in the gradient descent model? how do we choose it? should it be $0.01$ or $0.05$, for example? We do not know! The hyperparameter is defined based on your prior knowledge of the problem or by try and error!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e1a2ef",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "Can you find five hyperparameters in the logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee25589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
