{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06829be6-6d35-48d8-87f6-110b2cd0c6a8",
   "metadata": {},
   "source": [
    "# Physics Informed Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e2f3a-1670-4546-9c22-8fa6756029c1",
   "metadata": {},
   "source": [
    "\n",
    "Physics Informed Neural Networks are constructed by encoding the constraints posed by a given differential equation and its boundary conditions into the loss function of a Fully Connected Network. This constraint guides the network to approximate the solution of the differential equation.\n",
    "\n",
    "For a system $ f $, with solution $ u(\\mathbf{x},t) $, governed by the following equation\n",
    "\n",
    "\\begin{align}\\label{eq:pde}\n",
    "f(u) &:=u_{t}+\\mathcal{N}[u;\\lambda], \\mathbf{x} \\in \\Omega, t \\in [0,T] \\\\\n",
    "f(u) &= 0\n",
    "\\end{align} \n",
    "where $\\mathcal{N}[u;\\lambda]$ is a differential operator parameterised by $ \\lambda $, $ \\Omega \\in \\mathbb{R^D} $, $ \\mathbf{x} = (x_1,x_2,...,x_d) $ with boundary conditions \n",
    " \\begin{equation}\n",
    "\\mathcal{B}(u, \\mathbf{x},t)=0 \\quad \\text { on } \\quad \\partial \\Omega\n",
    "\\end{equation}\n",
    " and initial conditions\n",
    " \\begin{equation}\n",
    "\\mathcal{T}(u, \\mathbf{x},t)=0 \\quad \\text { at } \\quad t = 0\n",
    "\\end{equation}\n",
    "\n",
    "A neural network $u_{net}: \\mathbb{R}^{D+1}\\mapsto \\mathbb{R}^{1}$ is constructed as a surrogate model for the true solution $u$, \n",
    "\\begin{equation}\n",
    "f_{net}=f(u_{net})\n",
    "\\end{equation}\n",
    "The constraints imposed by the system are encoded in the loss term $L$ for neural network optimisation\n",
    "\\begin{equation}\n",
    "L={\\color{green} L_{f}}+{\\color{red} L_{BC}}+{\\color{blue} L_{IC}}\n",
    "\\label{eq:pinn_loss}\n",
    "\\end{equation}\n",
    "where $L_{f}$ denotes the error in the solution within the interior points of the system, enforcing the PDE. This error is calculated for $N_f$ collocation points.\n",
    "\\begin{equation}\n",
    "\\color{green} \n",
    "L_{f}=\\frac{1}{N_{f}} \\sum_{i=1}^{N_{f}}\\left|f_{net}\\left(\\mathbf{x}_{f}^{i}, t_{f}^{i}\\right)\\right|^{2}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\color{blue} \n",
    "L_{BC}=\\frac{1}{N_{BC}} \\sum_{i=1}^{N_{BC}}\\left|u\\left(\\mathbf{x}_{BC}^{i}, t_{BC}^{i}\\right)-u^{i}\\right|^{2}\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\color{red} \n",
    "L_{IC}=\\frac{1}{N_{IC}} \\sum_{i=1}^{N_{IC}}\\left|u\\left(\\mathbf{x}_{IC}^{i}, t_{IC}^{i}\\right)-u^{i}\\right|^{2}\n",
    "\\end{equation}\n",
    "$L_{BC}$ and $L_{IC}$ represent the constraints imposed by the boundary and initial conditions, calculated on a set of $N_{BC}$ boundary points and $N_{IC}$ initial points respectively, with $u_i$ being the ground truth.\n",
    "\n",
    "![Domains](fig/domains.png)\n",
    "\n",
    "Once sufficiently trained, the network can be used as a solver for the PDE, potentially for a range of parameters $ \\lambda $.\n",
    "\n",
    "![PINN architecture](fig/PINN_diagrams.png)\n",
    "\n",
    "Since PINNs can be used to solve systems of arbitrary resolutions once they are trained and generalise well over different parameter spaces, they might be used to accelerate the solution of PDEs. In the next section, the workflow for solving a simple system using PINNs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9ab57-97e4-4fdf-a900-b5ff9dfec850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
